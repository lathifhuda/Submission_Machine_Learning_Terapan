# -*- coding: utf-8 -*-
"""Prediksi_Stunting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uNwrchbyN60vlRkn2hKwH_-lLVwiCEx4

# Prediksi Risiko Stunting pada Balita Menggunakan Model Machine Learning
- **Nama:** Lathif Nurma Huda   
- **Email:** mc604d5y0872@student.devacademy.id
- **ID Dicoding:** MC604D5Y0872

Proyek ini bertujuan untuk membangun model prediktif guna mengidentifikasi risiko stunting pada balita berdasarkan data demografi dan kesehatan. Dataset diambil dari [Kaggle - Stunting Balita Detection ](https://www.kaggle.com/datasets/rendiputra/stunting-balita-detection-121k-rows).

## Import Library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import warnings
warnings.filterwarnings('ignore')

!pip install -q kaggle

"""## Data Loading"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d rendiputra/stunting-balita-detection-121k-rows

import zipfile
import os

zip_path = "stunting-balita-detection-121k-rows.zip"
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("stunting_dataset")

# Lihat isi folder
os.listdir("stunting_dataset")

df = pd.read_csv("stunting_dataset/data_balita.csv")

# Ambil sampel 5000 baris data secara acak
df_sample = df.sample(n=5000, random_state=42)

# Tampilkan 5 baris pertama sampel
df_sample.head()

from sklearn.model_selection import train_test_split

# Stratified sampling (ambil 5000 baris dengan proporsi target yang sama)
df_sample, _ = train_test_split(df, train_size=5000, stratify=df['Status Gizi'], random_state=42)

# Cek distribusi label setelah sampling
df_sample['Status Gizi'].value_counts(normalize=True)

df_sample.to_csv("stunting_sampled.csv", index=False)

df = pd.read_csv('stunting_sampled.csv')
df_sample = df.sample(n=5000, random_state=42)

"""## Exploratory Data Analysis"""

df

df.info()

df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()
df.rename(columns={
    'umur_(bulan)': 'umur',
    'tinggi_badan_(cm)': 'tinggi_badan',
    'status_gizi': 'stunting'  # jika ini adalah label target
}, inplace=True)

df.describe()

df.duplicated().sum()

# Hapus semua baris duplikat
df = df.drop_duplicates()

# Cek ulang jumlah duplikat setelah penghapusan
print("Jumlah duplikat setelah dibersihkan:", df.duplicated().sum())

df.isnull().sum()

"""## Menangani Outlier"""

# Boxplot untuk kolom 'tinggi_badan'
plt.figure(figsize=(8, 4))
sns.boxplot(x=df['tinggi_badan'])
plt.title('Boxplot Tinggi Badan')
plt.show()

# Boxplot untuk kolom 'umur'
plt.figure(figsize=(8, 4))
sns.boxplot(x=df['umur'])
plt.title('Boxplot Umur')
plt.show()

# Fungsi untuk menghapus outlier berdasarkan IQR
def remove_outliers_iqr(dataframe, column):
    Q1 = dataframe[column].quantile(0.25)
    Q3 = dataframe[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Filter data
    return dataframe[(dataframe[column] >= lower_bound) & (dataframe[column] <= upper_bound)]

# Hapus outlier dari kolom 'tinggi_badan' dan 'umur'
df = remove_outliers_iqr(df, 'tinggi_badan')
df = remove_outliers_iqr(df, 'umur')

# Cek jumlah data setelah pembersihan
print("Jumlah data setelah menghapus outlier:", len(df))

"""## Univariate Analysis

### Kolom Numerik
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""### Kolom kategorikal"""

categorical_cols = ['jenis_kelamin', 'stunting']

for col in categorical_cols:
    plt.figure(figsize=(5,4))
    sns.countplot(x=col, data=df, palette='Set3')
    plt.title(f'Distribusi {col}')
    plt.xlabel(col)
    plt.ylabel('Jumlah')
    plt.show()

"""### Multivariate Analysis"""

#Distribusi tinggi badan terhadap status gizi
plt.figure(figsize=(8, 5))
sns.boxplot(x='stunting', y='tinggi_badan', data=df, palette='Set3')
plt.title('Distribusi Tinggi Badan berdasarkan Status Gizi')
plt.xlabel('Status Gizi')
plt.ylabel('Tinggi Badan (cm)')
plt.show()

#Distribusi umur terhadap status gizi
plt.figure(figsize=(8, 5))
sns.boxplot(x='stunting', y='umur', data=df, palette='Set2')
plt.title('Distribusi Umur berdasarkan Status Gizi')
plt.xlabel('Status Gizi')
plt.ylabel('Umur (bulan)')
plt.show()

#Perbandingan Status Gizi dan Jenis Kelamin
plt.figure(figsize=(6, 4))
sns.countplot(x='stunting', hue='jenis_kelamin', data=df, palette='pastel')
plt.title('Perbandingan Status Gizi berdasarkan Jenis Kelamin')
plt.xlabel('Status Gizi')
plt.ylabel('Jumlah')
plt.legend(title='Jenis Kelamin')
plt.show()

#Scatterplot Umur vs Tinggi Badan, dipisah berdasarkan Status Gizi
plt.figure(figsize=(8, 5))
sns.scatterplot(x='umur', y='tinggi_badan', hue='stunting', data=df, palette='Set1')
plt.title('Umur vs Tinggi Badan berdasarkan Status Gizi')
plt.xlabel('Umur (bulan)')
plt.ylabel('Tinggi Badan (cm)')
plt.legend(title='Stunting')
plt.show()

sns.pairplot(df, diag_kind='kde', hue='stunting')

# Korelasi dan heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(df[['umur', 'tinggi_badan']].corr(), annot=True, cmap='coolwarm')
plt.title('Korelasi antar Variabel Numerik')
plt.show()

"""## Data Preparation

### Encoding kolom kategorikal
"""

from sklearn.preprocessing import LabelEncoder

le_jenis_kelamin = LabelEncoder()
le_stunting = LabelEncoder()

df['jenis_kelamin'] = le_jenis_kelamin.fit_transform(df['jenis_kelamin'])  # L, P -> 0, 1
df['stunting'] = le_stunting.fit_transform(df['stunting'])  # Normal, Stunting -> 0, 1 (misal)

print(df['jenis_kelamin'].unique())
print(df['stunting'].unique())

"""### Split Train Test"""

X = df.drop('stunting', axis=1)  # Fitur
y = df['stunting']               # Target

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Total jumlah sampel dalam dataset keseluruhan: {len(X)}")
print(f"Total jumlah sampel dalam dataset pelatihan (train): {len(X_train)}")
print(f"Total jumlah sampel dalam dataset pengujian (test): {len(X_test)}")

"""### Normalisasi"""

from sklearn.preprocessing import StandardScaler

# Daftar kolom numerik
numerical_features = ['umur', 'tinggi_badan']

# Inisialisasi dan fit scaler pada data latih
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])

# Transformasi data latih dan data uji
X_train[numerical_features] = scaler.transform(X_train[numerical_features])
X_test[numerical_features] = scaler.transform(X_test[numerical_features])

# Tampilkan 5 baris pertama data yang telah dinormalisasi
X_train[numerical_features].head()

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Inisialisasi model
knn = KNeighborsClassifier()
rf = RandomForestClassifier(random_state=42)
gb = GradientBoostingClassifier(random_state=42)

# Melatih model
knn.fit(X_train, y_train)
rf.fit(X_train, y_train)
gb.fit(X_train, y_train)

# Prediksi
knn_pred_train = knn.predict(X_train)
knn_pred_test  = knn.predict(X_test)

rf_pred_train = rf.predict(X_train)
rf_pred_test  = rf.predict(X_test)

gb_pred_train = gb.predict(X_train)
gb_pred_test  = gb.predict(X_test)

# Menyimpan skor akurasi
models = pd.DataFrame(index=['train_accuracy', 'test_accuracy'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

models.loc['train_accuracy', 'KNN'] = accuracy_score(y_train, knn_pred_train)
models.loc['test_accuracy', 'KNN']  = accuracy_score(y_test, knn_pred_test)

models.loc['train_accuracy', 'RandomForest'] = accuracy_score(y_train, rf_pred_train)
models.loc['test_accuracy', 'RandomForest']  = accuracy_score(y_test, rf_pred_test)

models.loc['train_accuracy', 'Boosting'] = accuracy_score(y_train, gb_pred_train)
models.loc['test_accuracy', 'Boosting']  = accuracy_score(y_test, gb_pred_test)

"""## Evaluasi Model"""

# Tampilkan hasil
print("Hasil akurasi masing-masing model:\n")
print(models)

plt.bar('KNN', models['KNN'])
plt.bar('RandomForest', models['RandomForest'])
plt.bar('Boosting', models['Boosting'])
plt.title("Perbandingan Akurasi Model");
plt.xlabel('Model');
plt.ylabel('Akurasi');
plt.show()